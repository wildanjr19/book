{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Coding Attention Mechanism ##"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BAB 3  \n",
    "1. Alasan mengapa menggunakan attention mechanism di neural networks\n",
    "2. Dasar self-attention, hingga self-attention lanjut\n",
    "3. Causal attention module yang menjadikan LLM generate satu token pada satu waktu\n",
    "4. Menghindari overfitting dengan cara masking random\n",
    "5. Menumpuk beberapa attention hingga menjadi multi-head attention"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Beberapa metode Attention :  \n",
    "1. Simplified self-attention : introduce the border ide\n",
    "2. Self-attention : self-attention dengan bobot yang trainable dan merupakan basis yang digunakan dalam LLMs\n",
    "3. Causal attention : menjadikan model untuk hanya mempertimbangkan input sebelumnya dan input saat ini pada urutan\n",
    "4. Multi-head attention : secara simultan menghitung informasi dari representasi yang berbeda (multi self attention)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 The problem with modeling long sequences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ambil contoh kita ingin membuat sebuah model penerjemah dari dua bahasa yang berbeda. Tidak mungkin kita menerjemahkan bahasa secara kata demi kata, karena menerjemahkan bahasa memerlukan pemahaman konteks dan grammar. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Untuk mengatasi masalah ini, sangat umum menggunakan deep neural networks dengan dua submodules yaitu *encoder* dan *decoder*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sebelum ditemukannya Tranformers, Recurrent Neural Networks (RNN) adalah algoritma yang paling populer untuk arsitektur *encoder-decoder* dalam kasus terjemahan. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dalam sebuah RNN encoder-decoder, teks input dimasukkan ke dalam encoder, yang memprosesnya secara berurutan. Encoder memperbarui keadaan tersembunyinya (nilai internal pada lapisan tersembunyi) di setiap langkah, berusaha menangkap seluruh makna kalimat input dalam keadaan tersembunyi terakhir, seperti yang diilustrasikan pada gambar 3.4. Decoder kemudian mengambil keadaan tersembunyi terakhir ini untuk mulai menghasilkan kalimat terjemahan, satu kata pada satu waktu. Decoder juga memperbarui keadaan tersembunyinya di setiap langkah, yang seharusnya membawa konteks yang diperlukan untuk prediksi kata berikutnya."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tidak dapat mengakses secara langsung keadaan tersembunyi sebelumnya dari encoder selama fase decoding. Akibatnya, ia hanya bergantung pada keadaan tersembunyi saat ini, yang merangkum semua informasi yang relevan. Hal ini dapat menyebabkan hilangnya konteks, terutama dalam kalimat kompleks di mana ketergantungan mungkin mencakup jarak yang jauh."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Capturing data dependencies with attention mechanisms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bahdanau Attention Mechanism (2014) memodifikasi *encoder-decoder* RNN, dimana *decoder* dapat dengan selektif mengakses bagian yang berbeda dari urutan input pada setiap proses decoding. Pada teks generator, *decoder* dapat dengan selektif mengakses input token. Ini berarti beberapa token lebih penting daripada yang lain untuk membuat sebuah output token. Seberapa penting ini ditentukan oleh **bobot perhatian/attention weights**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Attending to different parts of the input with self-attention"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.3.1 A simple self-attention mehcanism without trainable weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Membuat sebuah mekanisme self-attention sederhana tanpa weights. Nah, goals dari self-attention ini adalah untuk menghitung konteks vektor untuk setiap elemen input yang mengkombinasi informasi dari semua input yang lain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Self-attention akan mencari nilai attention-scores antar token input. Sebagai contoh AS12 - attention score antara X1 dan X2. X1, X2,...XN adalah sebuah token embedding dengan n_dimensional vector. Attention score akan menghasilkan skalar (satu nilai) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# token embeddings\n",
    "# with dimensions 6x3 (6 tokens, 3 dimensions)\n",
    "inputs = torch.tensor(\n",
    "    [[0.43, 0.15, 0.89], # Your (x1)\n",
    "     [0.55, 0.87, 0.66], # journey (x2)\n",
    "     [0.57, 0.85, 0.64], # starts (x3)\n",
    "     [0.22, 0.58, 0.33], # with (x4)\n",
    "     [0.77, 0.25, 0.10], # one (x5)\n",
    "     [0.05, 0.80, 0.55] # step (x6)\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- query token : token yang ingin dicari nilai attention scorenya terhadap token-token lain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.9544, 1.4950, 1.4754, 0.8434, 0.7070, 1.0865])\n"
     ]
    }
   ],
   "source": [
    "query = inputs[1] # second inputs (x2/journey) as the query\n",
    "\n",
    "attn_scores_2 = torch.empty(inputs.shape[0]) # shape[0] : 6 (number of tokens)\n",
    "\n",
    "# loop ini akan menghitung dot antara query dan setiap token\n",
    "# kemudian dimasukkan ke dalam attn_scores_2\n",
    "for i, x_i in enumerate(inputs):\n",
    "    attn_scores_2[i] = torch.dot(x_i,query)\n",
    "\n",
    "print(attn_scores_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NB** : Dot product akan menghasilkan scalar. Nilai dari dot product ini akan memberikan nilai/arti kesamaan (similiarty), karena menjelaskan bagaimana dekatnya dua vektor yang sejajar. Dalam konteks self-attention nilai dot product menentukan sejauh mana setiap elemen dalam suatu urutan berfokus pada, atau “memperhatikan,” elemen lainnya: semakin tinggi produk titik, semakin tinggi pula skor kesamaan dan perhatian antara dua elemen."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next step adalah menormalisasi setiap attention-score sehingga ketika dijumlahkan hasilnya 1. Ini berguna untuk kestabilan dalam pelatihan LLM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attention weights :  tensor([0.1455, 0.2278, 0.2249, 0.1285, 0.1077, 0.1656])\n",
      "Sum :  tensor(1.0000)\n"
     ]
    }
   ],
   "source": [
    "attn_weights_2_tmp = attn_scores_2 / attn_scores_2.sum()\n",
    "print('Attention weights : ', attn_weights_2_tmp)\n",
    "print('Sum : ', attn_weights_2_tmp.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attention weights (softmax naive) :  tensor([0.1385, 0.2379, 0.2333, 0.1240, 0.1082, 0.1581])\n",
      "Sum :  tensor(1.)\n"
     ]
    }
   ],
   "source": [
    "# softmax\n",
    "def softmax_naive(x):\n",
    "    return torch.exp(x) / torch.exp(x).sum(dim=0)\n",
    "\n",
    "attn_weights_2_naive = softmax_naive(attn_scores_2)\n",
    "print('Attention weights (softmax naive) : ', attn_weights_2_naive)\n",
    "print('Sum : ', attn_weights_2_naive.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attention weights (softmax) :  tensor([0.1385, 0.2379, 0.2333, 0.1240, 0.1082, 0.1581])\n",
      "Sum :  tensor(1.)\n"
     ]
    }
   ],
   "source": [
    "attn_weights_2 = torch.softmax(attn_scores_2, dim=0)\n",
    "print('Attention weights (softmax) : ', attn_weights_2)\n",
    "print('Sum : ', attn_weights_2.sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Last step menghitung context vector (z) dengn cara mengkalilkan input token embedding (x) dengan hasil dari attention-weights dan kemudian menjumlahkan vectornya."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.4419, 0.6515, 0.5683])\n"
     ]
    }
   ],
   "source": [
    "query = inputs[1] # second inputs (x2/journey) as the query\n",
    "context_vec_2 = torch.zeros(query.shape)\n",
    "for i, x_i in enumerate(inputs):\n",
    "    context_vec_2 += attn_weights_2[i] * x_i\n",
    "print(context_vec_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hasil diatas adalah hasil context vector kedua karena attention-weights computed with respect to the secod input vector in the previous step"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.3.2 Computing attention weights for all input tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) Compute attention scores\n",
    "2) Compute attention weights\n",
    "3) Compute context vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.9995, 0.9544, 0.9422, 0.4753, 0.4576, 0.6310],\n",
      "        [0.9544, 1.4950, 1.4754, 0.8434, 0.7070, 1.0865],\n",
      "        [0.9422, 1.4754, 1.4570, 0.8296, 0.7154, 1.0605],\n",
      "        [0.4753, 0.8434, 0.8296, 0.4937, 0.3474, 0.6565],\n",
      "        [0.4576, 0.7070, 0.7154, 0.3474, 0.6654, 0.2935],\n",
      "        [0.6310, 1.0865, 1.0605, 0.6565, 0.2935, 0.9450]])\n"
     ]
    }
   ],
   "source": [
    "# 1\n",
    "attn_scores = torch.empty(6, 6) # same as attn_scores_2 but for all tokens\n",
    "for i, x_i in enumerate(inputs):\n",
    "    for j, x_j in enumerate(inputs):\n",
    "        attn_scores[i][j] = torch.dot(x_i,x_j)\n",
    "\n",
    "print(attn_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hasil diatas merupakan representasi dari attention-score antara setiap pasangan input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.2098, 0.2006, 0.1981, 0.1242, 0.1220, 0.1452],\n",
      "        [0.1385, 0.2379, 0.2333, 0.1240, 0.1082, 0.1581],\n",
      "        [0.1390, 0.2369, 0.2326, 0.1242, 0.1108, 0.1565],\n",
      "        [0.1435, 0.2074, 0.2046, 0.1462, 0.1263, 0.1720],\n",
      "        [0.1526, 0.1958, 0.1975, 0.1367, 0.1879, 0.1295],\n",
      "        [0.1385, 0.2184, 0.2128, 0.1420, 0.0988, 0.1896]])\n"
     ]
    }
   ],
   "source": [
    "# 2\n",
    "# normalize\n",
    "attn_weights = torch.softmax(attn_scores, dim=1)\n",
    "print(attn_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.4421, 0.5931, 0.5790],\n",
      "        [0.4419, 0.6515, 0.5683],\n",
      "        [0.4431, 0.6496, 0.5671],\n",
      "        [0.4304, 0.6298, 0.5510],\n",
      "        [0.4671, 0.5910, 0.5266],\n",
      "        [0.4177, 0.6503, 0.5645]])\n"
     ]
    }
   ],
   "source": [
    "# 3\n",
    "all_context_vecs = attn_weights @ inputs\n",
    "print(all_context_vecs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4 Implementing self-attention with trainable weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mekanisme self-attention yang paling popouler digunakan adalah **scaled dot-product attention**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.4.1 Computing the attention weights step by step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_2 = inputs[1] # second inputs (x2/journey) as the query\n",
    "d_in = inputs.shape[1] # 3\n",
    "d_out = 2 # the output embedding size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize three weight matrices (Wq, Wk, Wv)\n",
    "torch.manual_seed(123) # for reproducibility\n",
    "W_query = torch.nn.Parameter(torch.rand(d_in, d_out), requires_grad=False)\n",
    "W_key = torch.nn.Parameter(torch.rand(d_in,d_out), requires_grad=False)\n",
    "W_value = torch.nn.Parameter(torch.rand(d_in, d_out), requires_grad=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query :  tensor([0.4306, 1.4551])\n",
      "Key :  tensor([0.4433, 1.1419])\n",
      "Value :  tensor([0.3951, 1.0037])\n"
     ]
    }
   ],
   "source": [
    "# compute query, key, value vectors\n",
    "query_2 = x_2 @ W_query\n",
    "key_2 = x_2 @ W_key\n",
    "value_2 = x_2 @ W_value\n",
    "print('Query : ', query_2)\n",
    "print('Key : ', key_2)  \n",
    "print('Value : ', value_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keys shape :  torch.Size([6, 2])\n",
      "Values shape :  torch.Size([6, 2])\n"
     ]
    }
   ],
   "source": [
    "# obtain all keys and values\n",
    "keys = inputs @ W_key\n",
    "values = inputs @ W_value\n",
    "print('Keys shape : ', keys.shape)\n",
    "print('Values shape : ', values.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute attention-score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.8524)\n"
     ]
    }
   ],
   "source": [
    "# first, compute attention-scores 22\n",
    "keys_2 = keys[1] # second input \n",
    "attn_score_22 = query_2.dot(keys_2) # dot product between query and key\n",
    "print(attn_score_22)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1.2705, 1.8524, 1.8111, 1.0795, 0.5577, 1.5440])\n"
     ]
    }
   ],
   "source": [
    "# computation all attention score via matrix multiplication\n",
    "\n",
    "attn_scores_2 = query_2 @ keys.T # all attention scores for given query\n",
    "print(attn_scores_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sekarang kita berlanjut dari attention-scores menjadi attention-weights. Kita menghitung attentionn-weights dengan menggunakan softmax function. Untuk saat ini kita membagi attention-scores dengan akar kuadrat dari dimensi key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.1500, 0.2264, 0.2199, 0.1311, 0.0906, 0.1820])\n"
     ]
    }
   ],
   "source": [
    "d_k = keys.shape[-1]\n",
    "attn_weights_2 = torch.softmax(attn_scores_2 / d_k**0.5, dim=-1)\n",
    "print(attn_weights_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NB : Alasan mengapa dilakukan normalisasi dengan dimensi embedding adalah untuk meningkatkan performa pelatihan dengan menghindari gradient yang sangat kecil. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Last step adalah menghitung context-vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.3061, 0.8210])\n"
     ]
    }
   ],
   "source": [
    "context_vec_2 = attn_weights_2 @ values\n",
    "print(context_vec_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class SelfAttention_v1(nn.Module):\n",
    "    def __init__(self, d_in, d_out):\n",
    "        super().__init__()\n",
    "        self.W_query = nn.Parameter(torch.rand(d_in, d_out))\n",
    "        self.W_key = nn.Parameter(torch.rand(d_in, d_out))\n",
    "        self.W_value = nn.Parameter(torch.rand(d_in, d_out))\n",
    "\n",
    "    def forward(self, x):\n",
    "        keys = x @ self.W_key\n",
    "        queries = x @ self.W_query\n",
    "        values = x @ self.W_value\n",
    "\n",
    "        attn_scores = queries @ keys.T \n",
    "        attn_weights = torch.softmax(attn_scores / keys.shape[-1]**0.5, dim=-1)\n",
    "        context_vect = attn_weights @ values\n",
    "        return context_vect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.2996, 0.8053],\n",
      "        [0.3061, 0.8210],\n",
      "        [0.3058, 0.8203],\n",
      "        [0.2948, 0.7939],\n",
      "        [0.2927, 0.7891],\n",
      "        [0.2990, 0.8040]], grad_fn=<MmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "\n",
    "sa_v1 = SelfAttention_v1(d_in, d_out)\n",
    "print(sa_v1(inputs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alih-alih memakai nn.Parameter(torch.rand()) lebih baik menggunakan nn.Linear, karena memiliki optimasi yang baik dalam inisialisasi bobot yang dapat berkontribusi pada pelatihan yang lebih efektif dan stabil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SelfAttention_v2(nn.Module):\n",
    "    def __init__(self, d_in, d_out, qkv_bias = False):\n",
    "        super().__init__()\n",
    "        self.W_query = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
    "        self.W_key = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
    "        self.W_value = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
    "\n",
    "    def forward(self, x):\n",
    "        keys = self.W_key(x)\n",
    "        queries = self.W_query(x)\n",
    "        values = self.W_value(x)\n",
    "\n",
    "        attn_scores = queries @ keys.T \n",
    "        attn_weights = torch.softmax(attn_scores / keys.shape[-1]**0.5, dim=-1)\n",
    "        context_vect = attn_weights @ values\n",
    "        return context_vect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.0739,  0.0713],\n",
      "        [-0.0748,  0.0703],\n",
      "        [-0.0749,  0.0702],\n",
      "        [-0.0760,  0.0685],\n",
      "        [-0.0763,  0.0679],\n",
      "        [-0.0754,  0.0693]], grad_fn=<MmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(789)\n",
    "\n",
    "sa_v2 = SelfAttention_v2(d_in, d_out)\n",
    "print(sa_v2(inputs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.5 Hiding future words with causal attention"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kebanyakan tugas dari LLM, meminta self-attention mechanism untuk hanya mempertimbangkan token yang posisinya muncul sebelum posisi saat ini ketika memprediksi token selanjutnya pada sebuah urutan."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Masked-attention adalah spesialisasi dari self attention, dimana model hanya akan mempertimbangkan input sebelumnya dan input saat ini pada sebuah urutan untuk mempertimbangkan attention score."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.5.1 Applying a causal attention mask"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Key idea untuk memperoleh masked-attention weight pada causal-attention adalah melakukan normalisasi pada attention scores, dan memberikan nilai 0 pada elemenent-element diatas diagonal utama dan melakukan normalisasi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.1921, 0.1646, 0.1652, 0.1550, 0.1721, 0.1510],\n",
      "        [0.2041, 0.1659, 0.1662, 0.1496, 0.1665, 0.1477],\n",
      "        [0.2036, 0.1659, 0.1662, 0.1498, 0.1664, 0.1480],\n",
      "        [0.1869, 0.1667, 0.1668, 0.1571, 0.1661, 0.1564],\n",
      "        [0.1830, 0.1669, 0.1670, 0.1588, 0.1658, 0.1585],\n",
      "        [0.1935, 0.1663, 0.1666, 0.1542, 0.1666, 0.1529]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n"
     ]
    }
   ],
   "source": [
    "queries = sa_v2.W_query(inputs)\n",
    "keys = sa_v2.W_key(inputs)\n",
    "\n",
    "attn_scores = queries @ keys.T\n",
    "attn_weights = torch.softmax(attn_scores / keys.shape[-1]**0.5, dim=-1)\n",
    "\n",
    "print(attn_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 0., 0., 0., 0., 0.],\n",
      "        [1., 1., 0., 0., 0., 0.],\n",
      "        [1., 1., 1., 0., 0., 0.],\n",
      "        [1., 1., 1., 1., 0., 0.],\n",
      "        [1., 1., 1., 1., 1., 0.],\n",
      "        [1., 1., 1., 1., 1., 1.]])\n"
     ]
    }
   ],
   "source": [
    "context_length = attn_scores.shape[0]\n",
    "\n",
    "mask_simple = torch.tril(torch.ones(context_length, context_length), diagonal=0)\n",
    "print(mask_simple)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.1921, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.2041, 0.1659, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.2036, 0.1659, 0.1662, 0.0000, 0.0000, 0.0000],\n",
      "        [0.1869, 0.1667, 0.1668, 0.1571, 0.0000, 0.0000],\n",
      "        [0.1830, 0.1669, 0.1670, 0.1588, 0.1658, 0.0000],\n",
      "        [0.1935, 0.1663, 0.1666, 0.1542, 0.1666, 0.1529]],\n",
      "       grad_fn=<MulBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# multiply attn_weights with mask_simple\n",
    "# to zero-out the value\n",
    "masked_simple = attn_weights * mask_simple\n",
    "print(masked_simple)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.5517, 0.4483, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.3800, 0.3097, 0.3103, 0.0000, 0.0000, 0.0000],\n",
      "        [0.2758, 0.2460, 0.2462, 0.2319, 0.0000, 0.0000],\n",
      "        [0.2175, 0.1983, 0.1984, 0.1888, 0.1971, 0.0000],\n",
      "        [0.1935, 0.1663, 0.1666, 0.1542, 0.1666, 0.1529]],\n",
      "       grad_fn=<DivBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# renormalize\n",
    "# sum up to 1 in each row\n",
    "row_sums  = masked_simple.sum(dim=-1, keepdim=True)\n",
    "masked_simple_norm = masked_simple / row_sums\n",
    "print(masked_simple_norm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cara yang lebih efisien untuk mendapatkan masked attention weight pada causal attention adalah melakukan masking pada attention-scores dengan nilai negatif infinity sebelum menggunakan fungsi softmax."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.2899,   -inf,   -inf,   -inf,   -inf,   -inf],\n",
      "        [0.4656, 0.1723,   -inf,   -inf,   -inf,   -inf],\n",
      "        [0.4594, 0.1703, 0.1731,   -inf,   -inf,   -inf],\n",
      "        [0.2642, 0.1024, 0.1036, 0.0186,   -inf,   -inf],\n",
      "        [0.2183, 0.0874, 0.0882, 0.0177, 0.0786,   -inf],\n",
      "        [0.3408, 0.1270, 0.1290, 0.0198, 0.1290, 0.0078]],\n",
      "       grad_fn=<MaskedFillBackward0>)\n"
     ]
    }
   ],
   "source": [
    "mask = torch.triu(torch.ones(context_length, context_length), diagonal=1)\n",
    "masked = attn_scores.masked_fill(mask.bool(), -torch.inf)\n",
    "print(masked)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.5517, 0.4483, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.3800, 0.3097, 0.3103, 0.0000, 0.0000, 0.0000],\n",
      "        [0.2758, 0.2460, 0.2462, 0.2319, 0.0000, 0.0000],\n",
      "        [0.2175, 0.1983, 0.1984, 0.1888, 0.1971, 0.0000],\n",
      "        [0.1935, 0.1663, 0.1666, 0.1542, 0.1666, 0.1529]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n"
     ]
    }
   ],
   "source": [
    "attn_weights = torch.softmax(masked / keys.shape[-1]**0.5, dim=1)\n",
    "print(attn_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setelah ini bisa menggunakan attention weights yang telah dimodifikasi untuk menghitung context-vector via `context_vec = attn_weights @ values`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.5.2 Masking additional attention weights with dropout"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dropout pada deep learning adalah sebuah teknik dimana secara random memilih unit hidden layer untuk diabaikan selama pelatihan, secara efektif \"dropping out\". Metode ini membantu untuk mencegah overfitting, sehingga model tidak terlalu bergantung pada semua hidden layer secara spesifik. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[2., 2., 2., 2., 2., 2.],\n",
      "        [0., 2., 0., 0., 0., 0.],\n",
      "        [0., 0., 2., 0., 2., 0.],\n",
      "        [2., 2., 0., 0., 0., 2.],\n",
      "        [2., 0., 0., 0., 0., 2.],\n",
      "        [0., 2., 0., 0., 0., 0.]])\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "\n",
    "dropout = torch.nn.Dropout(0.5) # 50% dropout rate - a half of matrix randomly set to zero\n",
    "example = torch.ones(6, 6)\n",
    "print(dropout(example))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[2.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.8966, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.6206, 0.0000, 0.0000, 0.0000],\n",
      "        [0.5517, 0.4921, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.4350, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.3327, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "       grad_fn=<MulBackward0>)\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "\n",
    "print(dropout(attn_weights))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.5.3 Implementing a compact causal attention class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 6, 3])\n"
     ]
    }
   ],
   "source": [
    "batch = torch.stack((inputs, inputs), dim=0)\n",
    "print(batch.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hasilnya adalah sebuah tensor 3 dimensi dengan komposisi 2 input teks, 6 token setiap teks, dan setiap token adalah vektor embedding 3 dimensi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CausalAttention(nn.Module):\n",
    "    def __init__(self, d_in, d_out, context_length, dropout, qkv_bias = False):\n",
    "        super().__init__()\n",
    "        self.d_out = d_out\n",
    "        self.W_query = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
    "        self.W_key = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
    "        self.W_value = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.register_buffer('mask', torch.triu(torch.ones(context_length, context_length), diagonal=1))\n",
    "\n",
    "    def forward(self, x):\n",
    "        b, num_tokens, d_in = x.shape\n",
    "        keys = self.W_key(x)\n",
    "        queries = self.W_query(x)\n",
    "        values = self.W_value(x)\n",
    "\n",
    "        attn_scores = queries @ keys.transpose(1, 2)\n",
    "        attn_scores.masked_fill_(self.mask.bool()[:num_tokens, :num_tokens], -torch.inf)\n",
    "        attn_weights = torch.softmax(attn_scores / keys.shape[-1]**0.5, dim=-1)\n",
    "        attn_weights = self.dropout(attn_weights)\n",
    "\n",
    "        context_vector = attn_weights @ values\n",
    "\n",
    "        return context_vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`register_buffer` berarti secara otomatis buffer dipindahlan ke perangkat yang sesuai (CPU atau GPU) bersamaan dengan model kita. Ini berarti kita tidak perlu memastikan tensor ini secara manual berada di perangkat yang sama dengan parameter model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Context_vecs.shape :  torch.Size([2, 6, 2])\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "\n",
    "context_length = batch.shape[1]\n",
    "\n",
    "ca = CausalAttention(d_in, d_out, context_length, 0.0)\n",
    "\n",
    "context_vecs = ca(batch)\n",
    "\n",
    "print(\"Context_vecs.shape : \", context_vecs.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hasilnya adalah context vector 3 dimensi dimana setiap token direpresentasikan dengan vector 2 dimensi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.6 Extending single-head attention to multi_head attention"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Multi-head attention berarti meng-expand Causal-attention kita menjadi beberapa 'head' dan beroperasi secara individu."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.6.1 Stacking multiple single-head attention layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttentionWrapper(nn.Module):\n",
    "    def __init__(self, d_in, d_out, context_length, dropout, num_heads, qkv_bias = False):\n",
    "        super().__init__()\n",
    "        self.heads = nn.ModuleList(CausalAttention(d_in, d_out, context_length, dropout, qkv_bias) for _ in range(num_heads))\n",
    "\n",
    "    def forward(self, x):\n",
    "        return torch.cat([head(x) for head in self.heads], dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Context_vecs.shape :  torch.Size([2, 6, 4])\n",
      "Context_vecs :  tensor([[[-0.4519,  0.2216,  0.4772,  0.1063],\n",
      "         [-0.5874,  0.0058,  0.5891,  0.3257],\n",
      "         [-0.6300, -0.0632,  0.6202,  0.3860],\n",
      "         [-0.5675, -0.0843,  0.5478,  0.3589],\n",
      "         [-0.5526, -0.0981,  0.5321,  0.3428],\n",
      "         [-0.5299, -0.1081,  0.5077,  0.3493]],\n",
      "\n",
      "        [[-0.4519,  0.2216,  0.4772,  0.1063],\n",
      "         [-0.5874,  0.0058,  0.5891,  0.3257],\n",
      "         [-0.6300, -0.0632,  0.6202,  0.3860],\n",
      "         [-0.5675, -0.0843,  0.5478,  0.3589],\n",
      "         [-0.5526, -0.0981,  0.5321,  0.3428],\n",
      "         [-0.5299, -0.1081,  0.5077,  0.3493]]], grad_fn=<CatBackward0>)\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "\n",
    "context_length = batch.shape[1] # number of tokens\n",
    "d_in, d_out = 3, 2\n",
    "\n",
    "mha = MultiHeadAttentionWrapper(d_in, d_out, context_length, 0.0, num_heads=2)\n",
    "\n",
    "context_vecs = mha(batch)\n",
    "\n",
    "print(\"Context_vecs.shape : \", context_vecs.shape)\n",
    "print(\"Context_vecs : \", context_vecs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dari hasil, tensor ini berdimensi 3 dengan komponen 2 teks, 6 tokens setiap teks, dan 4 dimensional vektor tiap token"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.6.2 Implementing multi-head attention with weight splits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Daripada kita me-maintanance dua kelas yang berbeda, kita akan menggabungkan dua konsep menjadi single MultiHeadAttention. CausakAttention memproses secara independen dan menggabungkan semuanya menjadi satu. Pada proses ini kita akan membagi menjadi beberapa kepala dengan mengubah bentuk  tensor **projected query, key, dan value** dan menggabungkannya setelah menghitung attention."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, d_in, d_out, context_length, dropout, num_heads, qkv_bias = False):\n",
    "        super().__init__()\n",
    "        assert (d_out % num_heads == 0), \"d_out must be divisible by num_heads\"\n",
    "\n",
    "        self.d_out = d_out\n",
    "        self.num_heads = num_heads\n",
    "        self.head_dim = d_out // num_heads # size of each attention-head\n",
    "        self.W_query = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
    "        self.W_key = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
    "        self.W_value = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
    "        self.out_proj = nn.Linear(d_out, d_out) # combine head output \n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.register_buffer('mask', torch.triu(torch.ones(context_length, context_length), diagonal=1))\n",
    "\n",
    "    def forward(self, x):\n",
    "        b, num_tokens, d_in = x.shape\n",
    "        keys = self.W_key(x)\n",
    "        queries = self.W_query(x)\n",
    "        values = self.W_value(x)\n",
    "        # tensor shape : (b, num_tokens, d_out)\n",
    "\n",
    "        keys = keys.view(b, num_tokens, self.num_heads, self.head_dim)\n",
    "        values = values.view(b, num_tokens, self.num_heads, self.head_dim)\n",
    "        queries = queries.view(b, num_tokens, self.num_heads, self.head_dim)\n",
    "        # secara implisit kita split matriks dengan menambah num_heads \n",
    "        # secara konseptual kita sedang memecah representasi embedding pada setiap token menjadi num_heads bagian\n",
    "\n",
    "        keys = keys.transpose(1, 2)\n",
    "        queries = queries.transpose(1, 2)\n",
    "        values = values.transpose(1, 2)\n",
    "        # kita menukar dimensi ke-1 dan ke-2 dari tensor keys, queries, dan values\n",
    "        # menjadi :  (b, num_heads, num_tokens, head_dim)\n",
    "\n",
    "        attn_scores = queries @ keys.transpose(2, 3)\n",
    "        mask_bool = self.mask.bool()[:num_tokens, :num_tokens]\n",
    "        attn_scores.masked_fill_(mask_bool, -torch.inf)\n",
    "\n",
    "        attn_weights = torch.softmax(attn_scores / keys.shape[-1]**0.5, dim=-1)\n",
    "        attn_weights = self.dropout(attn_weights)\n",
    "\n",
    "        context_vec = (attn_weights @ values).transpose(1, 2)\n",
    "\n",
    "        context_vec = context_vec.contiguous().view(b, num_tokens, self.d_out)\n",
    "\n",
    "        context_vec = self.out_proj(context_vec)\n",
    "\n",
    "        return context_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.tensor([[[[0.2745, 0.6584, 0.2775, 0.8573],   \n",
    "                    [0.8993, 0.0390, 0.9268, 0.7388],\n",
    "                    [0.7179, 0.7058, 0.9156, 0.4340]],\n",
    "\n",
    "                   [[0.0772, 0.3565, 0.1479, 0.5331],\n",
    "                    [0.4066, 0.2318, 0.4545, 0.9737],\n",
    "                    [0.4606, 0.5159, 0.4220, 0.5786]]]])\n",
    "# tensor with shape (b, num_heads, num_tokens, head_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[1.3208, 1.1631, 1.2879],\n",
      "          [1.1631, 2.2150, 1.8424],\n",
      "          [1.2879, 1.8424, 2.0402]],\n",
      "\n",
      "         [[0.4391, 0.7003, 0.5903],\n",
      "          [0.7003, 1.3737, 1.0620],\n",
      "          [0.5903, 1.0620, 0.9912]]]])\n"
     ]
    }
   ],
   "source": [
    "# perform a batched matrix multiplication\n",
    "# transpose the last two dimensions of a\n",
    "print(a @ a.transpose(2, 3))\n",
    "\n",
    "# the output have first head and second head in the same batch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Semua context-vector dari semua heads ditranspose kembali ke dalam bentuk (b, num_tokens, num_heads, head_dim). Tensor ini kemudian di-reshape (flattened) menjadi (b, num_tokens, d_out), secara efektif menggabungkan semua output dari setiap heads.  \n",
    "Selain itu, juga ditambahkan output projection layer (self.out_proj) setelah menggabungkan heads. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[0.3190, 0.4858],\n",
      "         [0.2943, 0.3897],\n",
      "         [0.2856, 0.3593],\n",
      "         [0.2693, 0.3873],\n",
      "         [0.2639, 0.3928],\n",
      "         [0.2575, 0.4028]],\n",
      "\n",
      "        [[0.3190, 0.4858],\n",
      "         [0.2943, 0.3897],\n",
      "         [0.2856, 0.3593],\n",
      "         [0.2693, 0.3873],\n",
      "         [0.2639, 0.3928],\n",
      "         [0.2575, 0.4028]]], grad_fn=<ViewBackward0>)\n",
      "Context vecs shape :  torch.Size([2, 6, 2])\n"
     ]
    }
   ],
   "source": [
    "# the MultiHeadAttention class can be used similiar to the SelfAttention and CausalAttention class\n",
    "torch.manual_seed(123)\n",
    "\n",
    "batch_size, context_length, d_in = batch.shape\n",
    "d_out = 2\n",
    "\n",
    "mha = MultiHeadAttention(d_in, d_out, context_length, 0.0, num_heads=2)\n",
    "context_vecs = mha(batch)\n",
    "\n",
    "print(context_vecs)\n",
    "print('Context vecs shape : ', context_vecs.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dari output dapat dilihat bahwa dimensi dari output itu sendiri secara langsung dikontrol oleh `d_out`"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
